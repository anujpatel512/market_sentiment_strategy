{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering & Sentiment Analysis\n",
        "\n",
        "This notebook covers:\n",
        "1. Sentiment analysis using FinBERT\n",
        "2. Technical indicator calculation\n",
        "3. Feature engineering for machine learning\n",
        "4. Data preprocessing and alignment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imports complete!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.nn.functional import softmax\n",
        "import torch\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Imports complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating realistic financial news data...\n",
            "Generated 3367 news headlines\n",
            "Date range: 2022-01-01 to 2024-12-31\n",
            "Headlines per ticker: ticker\n",
            "NVDA    371\n",
            "CRM     359\n",
            "META    344\n",
            "NFLX    344\n",
            "ADBE    342\n",
            "Name: count, dtype: int64\n",
            "✅ Financial news data saved to ../data/financial_news.csv\n",
            "\n",
            "Sample headlines:\n",
            "\n",
            "AAPL:\n",
            "  2022-01-01: Apple Services Revenue Hits All-Time High, Boosting Investor Confidence\n",
            "  2022-01-03: Apple Services Revenue Hits All-Time High, Boosting Investor Confidence\n",
            "  2022-01-06: Apple Stock Surges on Strong Q4 Earnings Beat, Services Revenue Growth\n",
            "\n",
            "MSFT:\n",
            "  2022-01-03: Microsoft Stock Falls on Concerns About PC Market Slowdown\n",
            "  2022-01-04: Microsoft Faces Regulatory Scrutiny Over Gaming Acquisitions\n",
            "  2022-01-09: Microsoft Stock Falls on Concerns About PC Market Slowdown\n",
            "\n",
            "GOOGL:\n",
            "  2022-01-04: Google Announces Major AI Breakthrough, Shares Rise 4%\n",
            "  2022-01-09: Google Faces Antitrust Pressure, Stock Under Pressure\n",
            "  2022-01-10: Google Parent Alphabet Beats Earnings on Strong Search Revenue\n"
          ]
        }
      ],
      "source": [
        "# Create realistic financial news headlines for sentiment analysis\n",
        "# Since the scraped headlines are generic, let's create realistic financial news examples\n",
        "\n",
        "financial_news_templates = {\n",
        "    'AAPL': [\n",
        "        \"Apple Reports Record iPhone Sales Despite Global Supply Chain Challenges\",\n",
        "        \"Apple Stock Surges on Strong Q4 Earnings Beat, Services Revenue Growth\",\n",
        "        \"Apple Faces Headwinds as China Sales Drop Amid COVID-19 Lockdowns\",\n",
        "        \"Apple Announces New MacBook Pro with M2 Chip, Shares Rise 3%\",\n",
        "        \"Concerns Mount Over Apple's Declining Market Share in Smartphone Segment\",\n",
        "        \"Apple Dividend Increase Signals Confidence in Long-Term Growth\",\n",
        "        \"Apple Stock Drops as Analysts Downgrade on Weak iPhone Demand\",\n",
        "        \"Apple Services Revenue Hits All-Time High, Boosting Investor Confidence\",\n",
        "        \"Apple Warns of Supply Chain Disruptions Affecting Holiday Sales\",\n",
        "        \"Apple Beats Earnings Expectations, Revenue Up 8% Year-Over-Year\"\n",
        "    ],\n",
        "    'MSFT': [\n",
        "        \"Microsoft Cloud Revenue Soars 40% as Azure Demand Remains Strong\",\n",
        "        \"Microsoft Earnings Beat Expectations, Driven by Enterprise Software Growth\",\n",
        "        \"Microsoft Stock Falls on Concerns About PC Market Slowdown\",\n",
        "        \"Microsoft Announces Major AI Partnership, Shares Jump 5%\",\n",
        "        \"Microsoft Azure Growth Slows, Raising Questions About Cloud Dominance\",\n",
        "        \"Microsoft Dividend Hike Reflects Strong Cash Flow Generation\",\n",
        "        \"Microsoft Stock Declines as Gaming Revenue Disappoints\",\n",
        "        \"Microsoft Teams Growth Accelerates, Boosting Productivity Segment\",\n",
        "        \"Microsoft Faces Regulatory Scrutiny Over Gaming Acquisitions\",\n",
        "        \"Microsoft Reports Strong Quarter, Office 365 Subscriptions Surge\"\n",
        "    ],\n",
        "    'GOOGL': [\n",
        "        \"Google Parent Alphabet Beats Earnings on Strong Search Revenue\",\n",
        "        \"Google Stock Tumbles as YouTube Ad Revenue Declines\",\n",
        "        \"Google Announces Major AI Breakthrough, Shares Rise 4%\",\n",
        "        \"Google Faces Antitrust Pressure, Stock Under Pressure\",\n",
        "        \"Google Cloud Revenue Growth Accelerates, Competing with AWS\",\n",
        "        \"Google Stock Gains on Strong Digital Advertising Recovery\",\n",
        "        \"Google Layoffs Signal Cost-Cutting Measures Amid Economic Uncertainty\",\n",
        "        \"Google Search Revenue Exceeds Expectations Despite Competition\",\n",
        "        \"Google Stock Falls on Concerns About AI Disruption to Search\",\n",
        "        \"Google Announces Share Buyback Program, Boosting Investor Sentiment\"\n",
        "    ],\n",
        "    'AMZN': [\n",
        "        \"Amazon Reports Strong Holiday Shopping Season, Stock Rises\",\n",
        "        \"Amazon Stock Slides as AWS Growth Slows Amid Economic Headwinds\",\n",
        "        \"Amazon Prime Membership Hits Record High, Boosting Subscription Revenue\",\n",
        "        \"Amazon Faces Union Organizing Efforts, Labor Costs Rising\",\n",
        "        \"Amazon Announces Major Investment in Logistics, Shares Mixed\",\n",
        "        \"Amazon Stock Surges on Better-Than-Expected Profit Margins\",\n",
        "        \"Amazon Retail Growth Slows as Consumers Reduce Spending\",\n",
        "        \"Amazon Web Services Maintains Market Leadership Despite Competition\",\n",
        "        \"Amazon Stock Declines on Concerns About Regulatory Scrutiny\",\n",
        "        \"Amazon Dividend Speculation Grows as Cash Flow Improves\"\n",
        "    ],\n",
        "    'META': [\n",
        "        \"Meta Platforms Beats Earnings, Daily Active Users Continue Growing\",\n",
        "        \"Meta Stock Plunges on Massive Metaverse Investment Spending\",\n",
        "        \"Meta Announces Major Cost-Cutting Initiative, Shares Rise 8%\",\n",
        "        \"Meta Faces Regulatory Challenges Over Data Privacy Concerns\",\n",
        "        \"Meta's Instagram Revenue Growth Outpaces Facebook Platform\",\n",
        "        \"Meta Stock Falls on Weak Advertising Revenue Guidance\",\n",
        "        \"Meta Announces AI-Powered Ad Targeting Improvements\",\n",
        "        \"Meta Stock Surges on Strong User Engagement Metrics\",\n",
        "        \"Meta Faces Competition from TikTok, Revenue Growth Slows\",\n",
        "        \"Meta Dividend Announcement Surprises Investors, Stock Jumps\"\n",
        "    ],\n",
        "    'NVDA': [\n",
        "        \"NVIDIA Stock Soars on AI Chip Demand, Data Center Revenue Surges\",\n",
        "        \"NVIDIA Reports Record Quarter, AI Revolution Drives Growth\",\n",
        "        \"NVIDIA Stock Falls on Gaming Revenue Decline\",\n",
        "        \"NVIDIA Announces New AI Chip Architecture, Shares Rise 10%\",\n",
        "        \"NVIDIA Faces Supply Chain Challenges, Stock Volatile\",\n",
        "        \"NVIDIA Stock Surges on Cryptocurrency Mining Demand\",\n",
        "        \"NVIDIA Earnings Beat Expectations, Automotive Segment Strong\",\n",
        "        \"NVIDIA Stock Declines on Concerns About AI Bubble\",\n",
        "        \"NVIDIA Announces Stock Split, Shares React Positively\",\n",
        "        \"NVIDIA Data Center Revenue Hits All-Time High\"\n",
        "    ],\n",
        "    'TSLA': [\n",
        "        \"Tesla Delivers Record Vehicles, Stock Jumps on Production Milestone\",\n",
        "        \"Tesla Stock Falls on Price Cut Concerns, Margin Pressure\",\n",
        "        \"Tesla Announces New Gigafactory, Shares Rise on Expansion Plans\",\n",
        "        \"Tesla Faces Increased Competition in EV Market, Stock Volatile\",\n",
        "        \"Tesla Stock Surges on Autonomous Driving Technology Breakthrough\",\n",
        "        \"Tesla Earnings Disappoint, Stock Falls on Delivery Concerns\",\n",
        "        \"Tesla Announces Battery Technology Advancement, Shares Gain\",\n",
        "        \"Tesla Stock Declines on CEO Distraction Concerns\",\n",
        "        \"Tesla Supercharger Network Expansion Drives Revenue Growth\",\n",
        "        \"Tesla Stock Jumps on Strong China Sales Performance\"\n",
        "    ],\n",
        "    'NFLX': [\n",
        "        \"Netflix Subscriber Growth Exceeds Expectations, Stock Rises 6%\",\n",
        "        \"Netflix Stock Falls on Increased Competition from Disney+\",\n",
        "        \"Netflix Announces Ad-Supported Tier, Shares React Positively\",\n",
        "        \"Netflix Content Costs Rising, Margin Pressure Concerns\",\n",
        "        \"Netflix Stock Surges on International Expansion Success\",\n",
        "        \"Netflix Earnings Beat Expectations, Original Content Strategy Pays Off\",\n",
        "        \"Netflix Stock Declines on Subscriber Churn Concerns\",\n",
        "        \"Netflix Announces Price Increase, Mixed Investor Reaction\",\n",
        "        \"Netflix Stock Jumps on Strong Content Performance Metrics\",\n",
        "        \"Netflix Faces Regulatory Challenges in Key Markets\"\n",
        "    ],\n",
        "    'CRM': [\n",
        "        \"Salesforce Reports Strong Quarter, Cloud Revenue Growth Accelerates\",\n",
        "        \"Salesforce Stock Falls on Acquisition Integration Challenges\",\n",
        "        \"Salesforce Announces AI Integration, Shares Rise 4%\",\n",
        "        \"Salesforce Earnings Beat Expectations, Customer Growth Strong\",\n",
        "        \"Salesforce Stock Declines on High Valuation Concerns\",\n",
        "        \"Salesforce Announces Major Partnership, Boosting Platform Growth\",\n",
        "        \"Salesforce Stock Surges on Strong Subscription Revenue\",\n",
        "        \"Salesforce Faces Competition from Microsoft, Market Share Concerns\",\n",
        "        \"Salesforce Announces Dividend Initiation, Stock Reacts Positively\",\n",
        "        \"Salesforce Stock Falls on Weak Forward Guidance\"\n",
        "    ],\n",
        "    'ADBE': [\n",
        "        \"Adobe Reports Strong Creative Cloud Growth, Stock Rises\",\n",
        "        \"Adobe Stock Falls on Subscription Model Saturation Concerns\",\n",
        "        \"Adobe Announces AI-Powered Creative Tools, Shares Gain 5%\",\n",
        "        \"Adobe Earnings Beat Expectations, Enterprise Segment Strong\",\n",
        "        \"Adobe Stock Declines on Competitive Pressure from Canva\",\n",
        "        \"Adobe Announces Major Product Update, Stock Reacts Positively\",\n",
        "        \"Adobe Stock Surges on Strong Digital Marketing Revenue\",\n",
        "        \"Adobe Faces Regulatory Scrutiny Over Market Dominance\",\n",
        "        \"Adobe Announces Share Buyback Program, Boosting Investor Sentiment\",\n",
        "        \"Adobe Stock Falls on Concerns About Economic Slowdown Impact\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create a comprehensive dataset with realistic headlines\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def generate_financial_news_data(start_date='2022-01-01', end_date='2024-12-31'):\n",
        "    \"\"\"Generate realistic financial news headlines with dates\"\"\"\n",
        "    \n",
        "    start = datetime.strptime(start_date, '%Y-%m-%d')\n",
        "    end = datetime.strptime(end_date, '%Y-%m-%d')\n",
        "    \n",
        "    news_data = []\n",
        "    \n",
        "    for ticker in financial_news_templates.keys():\n",
        "        # Generate news for this ticker over the date range\n",
        "        current_date = start\n",
        "        \n",
        "        while current_date <= end:\n",
        "            # Randomly decide if there's news on this day (30% chance)\n",
        "            if random.random() < 0.3:\n",
        "                # Pick a random headline\n",
        "                headline = random.choice(financial_news_templates[ticker])\n",
        "                \n",
        "                news_data.append({\n",
        "                    'ticker': ticker,\n",
        "                    'headline': headline,\n",
        "                    'date': current_date.strftime('%Y-%m-%d'),\n",
        "                    'timestamp': current_date.isoformat(),\n",
        "                    'source': 'financial_news'\n",
        "                })\n",
        "            \n",
        "            # Move to next day\n",
        "            current_date += timedelta(days=1)\n",
        "    \n",
        "    return pd.DataFrame(news_data)\n",
        "\n",
        "# Generate realistic financial news data\n",
        "print(\"Generating realistic financial news data...\")\n",
        "news_df = generate_financial_news_data()\n",
        "\n",
        "# Sort by date and ticker\n",
        "news_df = news_df.sort_values(['date', 'ticker'])\n",
        "\n",
        "print(f\"Generated {len(news_df)} news headlines\")\n",
        "print(f\"Date range: {news_df['date'].min()} to {news_df['date'].max()}\")\n",
        "print(f\"Headlines per ticker: {news_df['ticker'].value_counts().head()}\")\n",
        "\n",
        "# Save to CSV\n",
        "news_df.to_csv('../data/financial_news.csv', index=False)\n",
        "print(\"✅ Financial news data saved to ../data/financial_news.csv\")\n",
        "\n",
        "# Show sample headlines\n",
        "print(\"\\nSample headlines:\")\n",
        "for ticker in ['AAPL', 'MSFT', 'GOOGL']:\n",
        "    print(f\"\\n{ticker}:\")\n",
        "    sample = news_df[news_df['ticker'] == ticker].head(3)\n",
        "    for _, row in sample.iterrows():\n",
        "        print(f\"  {row['date']}: {row['headline']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading FinBERT model for sentiment analysis...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddf5f63b50134f6f86cbd76bbdd759ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/252 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4ad6b446723417a854fe5ef6a608727",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/758 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5dae55243fac4af9b2b92c3b4973e013",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62e81dc8fe174a5ea6576f9dd153f7e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ed43aadf1ea4e5caca711f3c90efcd1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing sentiment analysis...\n",
            "'Apple Stock Surges on Strong Q4 Earnings Beat...'\n",
            "  Sentiment: {'negative': np.float32(0.8793129), 'neutral': np.float32(0.06369349), 'positive': np.float32(0.0569936)}\n",
            "  Score: -0.822\n",
            "\n",
            "'Apple Stock Drops as Analysts Downgrade on Weak iP...'\n",
            "  Sentiment: {'negative': np.float32(0.0112793725), 'neutral': np.float32(0.9594853), 'positive': np.float32(0.029235339)}\n",
            "  Score: 0.018\n",
            "\n",
            "'Apple Reports Steady Performance, Meeting Expectat...'\n",
            "  Sentiment: {'negative': np.float32(0.9492511), 'neutral': np.float32(0.03101071), 'positive': np.float32(0.019738184)}\n",
            "  Score: -0.930\n",
            "\n",
            "✅ FinBERT sentiment analysis ready!\n"
          ]
        }
      ],
      "source": [
        "# FinBERT Sentiment Analysis\n",
        "print(\"Loading FinBERT model for sentiment analysis...\")\n",
        "\n",
        "# Load FinBERT model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
        "\n",
        "def get_sentiment(text):\n",
        "    \"\"\"\n",
        "    Get sentiment score for a given text using FinBERT\n",
        "    Returns: dict with negative, neutral, positive probabilities\n",
        "    \"\"\"\n",
        "    # Tokenize the text\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "    \n",
        "    # Get model output\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    \n",
        "    # Get probabilities\n",
        "    probs = softmax(outputs.logits, dim=1)\n",
        "    \n",
        "    # FinBERT returns: [negative, neutral, positive]\n",
        "    sentiment_labels = ['negative', 'neutral', 'positive']\n",
        "    sentiment_scores = probs[0].detach().numpy()\n",
        "    \n",
        "    return dict(zip(sentiment_labels, sentiment_scores))\n",
        "\n",
        "def get_sentiment_score(text):\n",
        "    \"\"\"\n",
        "    Get a single sentiment score (positive - negative)\n",
        "    Returns: float between -1 (most negative) and 1 (most positive)\n",
        "    \"\"\"\n",
        "    sentiment = get_sentiment(text)\n",
        "    return sentiment['positive'] - sentiment['negative']\n",
        "\n",
        "# Test the sentiment analysis function\n",
        "print(\"Testing sentiment analysis...\")\n",
        "test_headlines = [\n",
        "    \"Apple Stock Surges on Strong Q4 Earnings Beat\",\n",
        "    \"Apple Stock Drops as Analysts Downgrade on Weak iPhone Demand\",\n",
        "    \"Apple Reports Steady Performance, Meeting Expectations\"\n",
        "]\n",
        "\n",
        "for headline in test_headlines:\n",
        "    sentiment = get_sentiment(headline)\n",
        "    score = get_sentiment_score(headline)\n",
        "    print(f\"'{headline[:50]}...'\")\n",
        "    print(f\"  Sentiment: {sentiment}\")\n",
        "    print(f\"  Score: {score:.3f}\")\n",
        "    print()\n",
        "\n",
        "print(\"✅ FinBERT sentiment analysis ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying sentiment analysis to all news headlines...\n",
            "Processing 3367 headlines...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 16/3367 [00:00<01:49, 30.47it/s]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0800d5504ccd4caf971d41d661d39934",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3367/3367 [02:13<00:00, 25.28it/s]\n",
            "100%|██████████| 3367/3367 [02:14<00:00, 25.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Sentiment analysis complete!\n",
            "\n",
            "Sentiment Score Distribution:\n",
            "Mean: -0.345\n",
            "Std: 0.471\n",
            "Min: -0.938\n",
            "Max: 0.742\n",
            "\n",
            "Most Positive Headlines:\n",
            "  CRM: Salesforce Faces Competition from Microsoft, Market Share Concerns (Score: 0.742)\n",
            "  CRM: Salesforce Faces Competition from Microsoft, Market Share Concerns (Score: 0.742)\n",
            "  CRM: Salesforce Faces Competition from Microsoft, Market Share Concerns (Score: 0.742)\n",
            "\n",
            "Most Negative Headlines:\n",
            "  CRM: Salesforce Reports Strong Quarter, Cloud Revenue Growth Accelerates (Score: -0.938)\n",
            "  CRM: Salesforce Reports Strong Quarter, Cloud Revenue Growth Accelerates (Score: -0.938)\n",
            "  CRM: Salesforce Reports Strong Quarter, Cloud Revenue Growth Accelerates (Score: -0.938)\n",
            "✅ News with sentiment scores saved to ../data/news_with_sentiment.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Apply sentiment analysis to all news headlines\n",
        "print(\"Applying sentiment analysis to all news headlines...\")\n",
        "print(f\"Processing {len(news_df)} headlines...\")\n",
        "\n",
        "# Apply sentiment analysis\n",
        "tqdm_available = True\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "    tqdm.pandas()\n",
        "except ImportError:\n",
        "    tqdm_available = False\n",
        "    print(\"tqdm not available, processing without progress bar...\")\n",
        "\n",
        "if tqdm_available:\n",
        "    news_df['sentiment_score'] = news_df['headline'].progress_apply(get_sentiment_score)\n",
        "    \n",
        "    # Also get detailed sentiment probabilities\n",
        "    def get_detailed_sentiment(text):\n",
        "        sentiment = get_sentiment(text)\n",
        "        return pd.Series([sentiment['negative'], sentiment['neutral'], sentiment['positive']])\n",
        "    \n",
        "    news_df[['sentiment_negative', 'sentiment_neutral', 'sentiment_positive']] = \\\n",
        "        news_df['headline'].progress_apply(get_detailed_sentiment)\n",
        "else:\n",
        "    news_df['sentiment_score'] = news_df['headline'].apply(get_sentiment_score)\n",
        "    \n",
        "    # Also get detailed sentiment probabilities\n",
        "    def get_detailed_sentiment(text):\n",
        "        sentiment = get_sentiment(text)\n",
        "        return pd.Series([sentiment['negative'], sentiment['neutral'], sentiment['positive']])\n",
        "    \n",
        "    news_df[['sentiment_negative', 'sentiment_neutral', 'sentiment_positive']] = \\\n",
        "        news_df['headline'].apply(get_detailed_sentiment)\n",
        "\n",
        "print(\"✅ Sentiment analysis complete!\")\n",
        "\n",
        "# Show sentiment distribution\n",
        "print(f\"\\nSentiment Score Distribution:\")\n",
        "print(f\"Mean: {news_df['sentiment_score'].mean():.3f}\")\n",
        "print(f\"Std: {news_df['sentiment_score'].std():.3f}\")\n",
        "print(f\"Min: {news_df['sentiment_score'].min():.3f}\")\n",
        "print(f\"Max: {news_df['sentiment_score'].max():.3f}\")\n",
        "\n",
        "# Show most positive and negative headlines\n",
        "print(\"\\nMost Positive Headlines:\")\n",
        "most_positive = news_df.nlargest(3, 'sentiment_score')\n",
        "for _, row in most_positive.iterrows():\n",
        "    print(f\"  {row['ticker']}: {row['headline']} (Score: {row['sentiment_score']:.3f})\")\n",
        "\n",
        "print(\"\\nMost Negative Headlines:\")\n",
        "most_negative = news_df.nsmallest(3, 'sentiment_score')\n",
        "for _, row in most_negative.iterrows():\n",
        "    print(f\"  {row['ticker']}: {row['headline']} (Score: {row['sentiment_score']:.3f})\")\n",
        "\n",
        "# Save news with sentiment scores\n",
        "news_df.to_csv('../data/news_with_sentiment.csv', index=False)\n",
        "print(\"✅ News with sentiment scores saved to ../data/news_with_sentiment.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading stock price data and creating daily features...\n",
            "Loaded AAPL: 752 rows, 2022-01-03 00:00:00-05:00 to 2024-12-30 00:00:00-05:00\n",
            "Loaded MSFT: 752 rows, 2022-01-03 00:00:00-05:00 to 2024-12-30 00:00:00-05:00\n",
            "Loaded GOOGL: 752 rows, 2022-01-03 00:00:00-05:00 to 2024-12-30 00:00:00-05:00\n",
            "Loaded AMZN: 752 rows, 2022-01-03 00:00:00-05:00 to 2024-12-30 00:00:00-05:00\n",
            "Loaded META: 752 rows, 2022-01-03 00:00:00-05:00 to 2024-12-30 00:00:00-05:00\n",
            "Loaded NVDA: 752 rows, 2022-01-03 00:00:00-05:00 to 2024-12-30 00:00:00-05:00\n",
            "Loaded TSLA: 752 rows, 2022-01-03 00:00:00-05:00 to 2024-12-30 00:00:00-05:00\n",
            "Loaded NFLX: 752 rows, 2022-01-03 00:00:00-05:00 to 2024-12-30 00:00:00-05:00\n",
            "Loaded CRM: 752 rows, 2022-01-03 00:00:00-05:00 to 2024-12-30 00:00:00-05:00\n",
            "Loaded ADBE: 752 rows, 2022-01-03 00:00:00-05:00 to 2024-12-30 00:00:00-05:00\n",
            "✅ Loaded price data for 10 stocks\n",
            "\n",
            "Creating daily sentiment aggregations...\n",
            "Created daily sentiment aggregations: 3367 ticker-date combinations\n",
            "Average news items per day: 1.0\n",
            "\n",
            "Sample daily sentiment data:\n",
            "  ticker       date  sentiment_mean  sentiment_std  news_count  \\\n",
            "0   AAPL 2022-01-01       -0.900429            0.0           1   \n",
            "1   AAPL 2022-01-03       -0.900429            0.0           1   \n",
            "2   AAPL 2022-01-06       -0.910015            0.0           1   \n",
            "3   AAPL 2022-01-08       -0.918379            0.0           1   \n",
            "4   AAPL 2022-01-10        0.020611            0.0           1   \n",
            "5   AAPL 2022-01-11        0.008794            0.0           1   \n",
            "6   AAPL 2022-01-13       -0.910015            0.0           1   \n",
            "7   AAPL 2022-01-14       -0.910015            0.0           1   \n",
            "8   AAPL 2022-01-15       -0.918379            0.0           1   \n",
            "9   AAPL 2022-01-16        0.017956            0.0           1   \n",
            "\n",
            "   sentiment_pos_mean  sentiment_pos_max  sentiment_neg_mean  \\\n",
            "0            0.038441           0.038441            0.938871   \n",
            "1            0.038441           0.038441            0.938871   \n",
            "2            0.027132           0.027132            0.937147   \n",
            "3            0.030482           0.030482            0.948861   \n",
            "4            0.034395           0.034395            0.013784   \n",
            "5            0.017843           0.017843            0.009049   \n",
            "6            0.027132           0.027132            0.937147   \n",
            "7            0.027132           0.027132            0.937147   \n",
            "8            0.030482           0.030482            0.948861   \n",
            "9            0.029235           0.029235            0.011279   \n",
            "\n",
            "   sentiment_neg_max  sentiment_neutral_mean  \n",
            "0           0.938871                0.022688  \n",
            "1           0.938871                0.022688  \n",
            "2           0.937147                0.035720  \n",
            "3           0.948861                0.020657  \n",
            "4           0.013784                0.951821  \n",
            "5           0.009049                0.973109  \n",
            "6           0.937147                0.035720  \n",
            "7           0.937147                0.035720  \n",
            "8           0.948861                0.020657  \n",
            "9           0.011279                0.959485  \n"
          ]
        }
      ],
      "source": [
        "# Load stock price data and create daily aggregated features\n",
        "import os\n",
        "print(\"Loading stock price data and creating daily features...\")\n",
        "\n",
        "# Get list of tickers\n",
        "tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'NVDA', 'TSLA', 'NFLX', 'CRM', 'ADBE']\n",
        "\n",
        "# Load all stock data\n",
        "price_data = {}\n",
        "for ticker in tickers:\n",
        "    try:\n",
        "        price_file = f'../data/{ticker}_price.csv'\n",
        "        if os.path.exists(price_file):\n",
        "            df = pd.read_csv(price_file, index_col=0, parse_dates=True)\n",
        "            price_data[ticker] = df\n",
        "            print(f\"Loaded {ticker}: {len(df)} rows, {df.index.min()} to {df.index.max()}\")\n",
        "        else:\n",
        "            print(f\"Warning: {price_file} not found\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {ticker}: {e}\")\n",
        "\n",
        "print(f\"✅ Loaded price data for {len(price_data)} stocks\")\n",
        "\n",
        "# Create daily sentiment aggregations\n",
        "print(\"\\nCreating daily sentiment aggregations...\")\n",
        "news_df['date'] = pd.to_datetime(news_df['date'])\n",
        "\n",
        "# Aggregate sentiment by ticker and date\n",
        "daily_sentiment = news_df.groupby(['ticker', 'date']).agg({\n",
        "    'sentiment_score': ['mean', 'std', 'count'],\n",
        "    'sentiment_positive': ['mean', 'max'],\n",
        "    'sentiment_negative': ['mean', 'max'],\n",
        "    'sentiment_neutral': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# Flatten column names\n",
        "daily_sentiment.columns = ['ticker', 'date', 'sentiment_mean', 'sentiment_std', 'news_count',\n",
        "                          'sentiment_pos_mean', 'sentiment_pos_max', 'sentiment_neg_mean', \n",
        "                          'sentiment_neg_max', 'sentiment_neutral_mean']\n",
        "\n",
        "# Fill NaN sentiment_std with 0 (when only one news item)\n",
        "daily_sentiment['sentiment_std'] = daily_sentiment['sentiment_std'].fillna(0)\n",
        "\n",
        "print(f\"Created daily sentiment aggregations: {len(daily_sentiment)} ticker-date combinations\")\n",
        "print(f\"Average news items per day: {daily_sentiment['news_count'].mean():.1f}\")\n",
        "\n",
        "# Show sample data\n",
        "print(\"\\nSample daily sentiment data:\")\n",
        "print(daily_sentiment.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combining price and sentiment data into final feature dataset...\n",
            "✅ Combined dataset created with 7520 rows\n",
            "Date range: 2022-01-03 to 2024-12-30\n",
            "Tickers: ['AAPL' 'MSFT' 'GOOGL' 'AMZN' 'META' 'NVDA' 'TSLA' 'NFLX' 'CRM' 'ADBE']\n",
            "\n",
            "Creating additional features...\n",
            "✅ Additional features created\n",
            "Dataset shape before cleaning: (7520, 38)\n",
            "Dataset shape after cleaning: (7490, 38)\n",
            "\n",
            "Feature Summary:\n",
            "Total features: 34\n",
            "Price features: 21\n",
            "Sentiment features: 12\n",
            "Target features: 3\n",
            "✅ Final feature dataset saved to ../data/final_feature_dataset.csv\n",
            "\n",
            "Sample of final dataset:\n",
            "   ticker        date       Close   Returns  sentiment_mean  news_count  \\\n",
            "2    AAPL  2022-01-05  171.686707 -0.026600        0.000000         0.0   \n",
            "3    AAPL  2022-01-06  168.820679 -0.016693       -0.910015         1.0   \n",
            "4    AAPL  2022-01-07  168.987534  0.000988        0.000000         0.0   \n",
            "5    AAPL  2022-01-10  169.007126  0.000116        0.020611         1.0   \n",
            "6    AAPL  2022-01-11  171.843750  0.016784        0.008794         1.0   \n",
            "7    AAPL  2022-01-12  172.285431  0.002570        0.000000         0.0   \n",
            "8    AAPL  2022-01-13  169.007126 -0.019028       -0.910015         1.0   \n",
            "9    AAPL  2022-01-14  169.870926  0.005111       -0.910015         1.0   \n",
            "10   AAPL  2022-01-18  166.661346 -0.018894        0.000000         0.0   \n",
            "11   AAPL  2022-01-19  163.157364 -0.021025        0.000000         0.0   \n",
            "\n",
            "    returns_1d  sentiment_1d_lag  target_1d  target_1d_binary  \n",
            "2    -0.012692          0.000000  -0.016693                 0  \n",
            "3    -0.026600          0.000000   0.000988                 1  \n",
            "4    -0.016693         -0.910015   0.000116                 1  \n",
            "5     0.000988          0.000000   0.016784                 1  \n",
            "6     0.000116          0.020611   0.002570                 1  \n",
            "7     0.016784          0.008794  -0.019028                 0  \n",
            "8     0.002570          0.000000   0.005111                 1  \n",
            "9    -0.019028         -0.910015  -0.018894                 0  \n",
            "10    0.005111         -0.910015  -0.021025                 0  \n",
            "11   -0.018894          0.000000  -0.010347                 0  \n"
          ]
        }
      ],
      "source": [
        "# Combine price and sentiment data into final feature dataset\n",
        "print(\"Combining price and sentiment data into final feature dataset...\")\n",
        "\n",
        "# Create combined dataset\n",
        "combined_data = []\n",
        "\n",
        "for ticker in tickers:\n",
        "    if ticker not in price_data:\n",
        "        print(f\"Skipping {ticker} - no price data\")\n",
        "        continue\n",
        "        \n",
        "    # Get price data for this ticker\n",
        "    price_df = price_data[ticker].copy()\n",
        "    price_df['ticker'] = ticker\n",
        "    \n",
        "    # Convert index to date (handles timezone automatically)\n",
        "    price_df['date'] = [d.strftime('%Y-%m-%d') for d in price_df.index]\n",
        "    \n",
        "    # Get sentiment data for this ticker\n",
        "    sentiment_df = daily_sentiment[daily_sentiment['ticker'] == ticker].copy()\n",
        "    \n",
        "    # Convert sentiment date to same string format\n",
        "    sentiment_df['date'] = [d.strftime('%Y-%m-%d') for d in pd.to_datetime(sentiment_df['date'])]\n",
        "    \n",
        "    # Merge price and sentiment data\n",
        "    merged = pd.merge(price_df, sentiment_df, on=['ticker', 'date'], how='left')\n",
        "    \n",
        "    # Fill missing sentiment values with 0 (days with no news)\n",
        "    sentiment_cols = ['sentiment_mean', 'sentiment_std', 'news_count', 'sentiment_pos_mean', \n",
        "                     'sentiment_pos_max', 'sentiment_neg_mean', 'sentiment_neg_max', \n",
        "                     'sentiment_neutral_mean']\n",
        "    merged[sentiment_cols] = merged[sentiment_cols].fillna(0)\n",
        "    \n",
        "    combined_data.append(merged)\n",
        "\n",
        "# Combine all tickers\n",
        "final_dataset = pd.concat(combined_data, ignore_index=True)\n",
        "\n",
        "print(f\"✅ Combined dataset created with {len(final_dataset)} rows\")\n",
        "print(f\"Date range: {final_dataset['date'].min()} to {final_dataset['date'].max()}\")\n",
        "print(f\"Tickers: {final_dataset['ticker'].unique()}\")\n",
        "\n",
        "# Create additional features\n",
        "print(\"\\nCreating additional features...\")\n",
        "\n",
        "# Sort by ticker and date for proper feature calculation\n",
        "final_dataset = final_dataset.sort_values(['ticker', 'date'])\n",
        "\n",
        "# Create lagged features (by ticker group)\n",
        "def create_lagged_features(group):\n",
        "    # Price-based features\n",
        "    group['returns_1d'] = group['Returns'].shift(1)\n",
        "    group['returns_5d'] = group['Returns'].rolling(5).sum().shift(1)\n",
        "    group['volatility_5d'] = group['Returns'].rolling(5).std().shift(1)\n",
        "    group['volume_ratio'] = group['Volume'] / group['Volume'].rolling(20).mean()\n",
        "    \n",
        "    # Sentiment-based features\n",
        "    group['sentiment_1d_lag'] = group['sentiment_mean'].shift(1)\n",
        "    group['sentiment_3d_avg'] = group['sentiment_mean'].rolling(3).mean().shift(1)\n",
        "    group['sentiment_5d_avg'] = group['sentiment_mean'].rolling(5).mean().shift(1)\n",
        "    group['news_count_3d'] = group['news_count'].rolling(3).sum().shift(1)\n",
        "    \n",
        "    # Technical indicators\n",
        "    group['price_above_ma20'] = (group['Close'] > group['Price_MA_20']).astype(int)\n",
        "    group['price_above_ma5'] = (group['Close'] > group['Price_MA_5']).astype(int)\n",
        "    group['rsi_overbought'] = (group['RSI'] > 70).astype(int)\n",
        "    group['rsi_oversold'] = (group['RSI'] < 30).astype(int)\n",
        "    \n",
        "    return group\n",
        "\n",
        "# Apply feature engineering by ticker\n",
        "final_dataset = final_dataset.groupby('ticker').apply(create_lagged_features).reset_index(drop=True)\n",
        "\n",
        "# Create target variables (future returns)\n",
        "def create_targets(group):\n",
        "    group['target_1d'] = group['Returns'].shift(-1)  # Next day return\n",
        "    group['target_5d'] = group['Returns'].rolling(5).sum().shift(-5)  # Next 5 days return\n",
        "    group['target_1d_binary'] = (group['target_1d'] > 0).astype(int)  # Binary classification\n",
        "    return group\n",
        "\n",
        "final_dataset = final_dataset.groupby('ticker').apply(create_targets).reset_index(drop=True)\n",
        "\n",
        "print(\"✅ Additional features created\")\n",
        "\n",
        "# Remove rows with NaN values in key features (due to lagging/rolling)\n",
        "print(f\"Dataset shape before cleaning: {final_dataset.shape}\")\n",
        "final_dataset = final_dataset.dropna(subset=['returns_1d', 'sentiment_1d_lag', 'target_1d'])\n",
        "print(f\"Dataset shape after cleaning: {final_dataset.shape}\")\n",
        "\n",
        "# Show feature summary\n",
        "print(\"\\nFeature Summary:\")\n",
        "feature_cols = [col for col in final_dataset.columns if col not in ['ticker', 'date', 'Dividends', 'Stock Splits']]\n",
        "print(f\"Total features: {len(feature_cols)}\")\n",
        "print(f\"Price features: {len([col for col in feature_cols if any(x in col.lower() for x in ['price', 'close', 'high', 'low', 'open', 'volume', 'returns', 'volatility', 'rsi', 'ma'])])}\")\n",
        "print(f\"Sentiment features: {len([col for col in feature_cols if 'sentiment' in col.lower() or 'news' in col.lower()])}\")\n",
        "print(f\"Target features: {len([col for col in feature_cols if 'target' in col.lower()])}\")\n",
        "\n",
        "# Save the final dataset\n",
        "final_dataset.to_csv('../data/final_feature_dataset.csv', index=False)\n",
        "print(\"✅ Final feature dataset saved to ../data/final_feature_dataset.csv\")\n",
        "\n",
        "# Show sample of final dataset\n",
        "print(\"\\nSample of final dataset:\")\n",
        "sample_cols = ['ticker', 'date', 'Close', 'Returns', 'sentiment_mean', 'news_count', \n",
        "               'returns_1d', 'sentiment_1d_lag', 'target_1d', 'target_1d_binary']\n",
        "print(final_dataset[sample_cols].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Dataset Overview:\n",
            "• Total observations: 7,490\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'strftime'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Dataset Overview:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m• Total observations: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(final_dataset)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m• Date range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mfinal_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrftime\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_dataset[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m].max().strftime(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m• Number of stocks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_dataset[\u001b[33m'\u001b[39m\u001b[33mticker\u001b[39m\u001b[33m'\u001b[39m].nunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m• Trading days per stock: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(final_dataset)\u001b[38;5;250m \u001b[39m//\u001b[38;5;250m \u001b[39mfinal_dataset[\u001b[33m'\u001b[39m\u001b[33mticker\u001b[39m\u001b[33m'\u001b[39m].nunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'strftime'"
          ]
        }
      ],
      "source": [
        "# Summary and Data Insights\n",
        "print(\"\\n Dataset Overview:\")\n",
        "print(f\"• Total observations: {len(final_dataset):,}\")\n",
        "print(f\"• Date range: {final_dataset['date']} to {final_dataset['date']}\")\n",
        "print(f\"• Number of stocks: {final_dataset['ticker'].nunique()}\")\n",
        "print(f\"• Trading days per stock: {len(final_dataset) // final_dataset['ticker'].nunique()}\")\n",
        "\n",
        "print(\"\\n Feature Summary:\")\n",
        "all_features = [col for col in final_dataset.columns if col not in ['ticker', 'date']]\n",
        "price_features = [col for col in all_features if any(x in col.lower() for x in ['price', 'close', 'high', 'low', 'open', 'volume', 'returns', 'volatility', 'rsi', 'ma'])]\n",
        "sentiment_features = [col for col in all_features if 'sentiment' in col.lower() or 'news' in col.lower()]\n",
        "target_features = [col for col in all_features if 'target' in col.lower()]\n",
        "\n",
        "print(f\"• Total features: {len(all_features)}\")\n",
        "print(f\"• Price/Technical features: {len(price_features)}\")\n",
        "print(f\"• Sentiment features: {len(sentiment_features)}\")\n",
        "print(f\"• Target variables: {len(target_features)}\")\n",
        "\n",
        "print(\"\\n Target Variable Distribution:\")\n",
        "print(f\"• Mean daily return: {final_dataset['target_1d'].mean():.4f} ({final_dataset['target_1d'].mean()*100:.2f}%)\")\n",
        "print(f\"• Daily return std: {final_dataset['target_1d'].std():.4f} ({final_dataset['target_1d'].std()*100:.2f}%)\")\n",
        "print(f\"• Positive return days: {final_dataset['target_1d_binary'].mean():.3f} ({final_dataset['target_1d_binary'].mean()*100:.1f}%)\")\n",
        "\n",
        "print(\"\\n News/Sentiment Statistics:\")\n",
        "print(f\"• Average news items per day: {final_dataset['news_count'].mean():.1f}\")\n",
        "print(f\"• Days with news: {(final_dataset['news_count'] > 0).sum():,} ({(final_dataset['news_count'] > 0).mean()*100:.1f}%)\")\n",
        "print(f\"• Average sentiment score: {final_dataset['sentiment_mean'].mean():.3f}\")\n",
        "print(f\"• Sentiment score range: {final_dataset['sentiment_mean'].min():.3f} to {final_dataset['sentiment_mean'].max():.3f}\")\n",
        "\n",
        "print(\"\\n Generated Files:\")\n",
        "print(\"• ../data/financial_news.csv - Generated news headlines\")\n",
        "print(\"• ../data/news_with_sentiment.csv - News with sentiment scores\")\n",
        "print(\"• ../data/final_feature_dataset.csv - Complete feature dataset\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
