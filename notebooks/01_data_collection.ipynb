{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Collection - Stock Prices & News Headlines\n",
        "\n",
        "This notebook covers:\n",
        "1. Downloading historical stock price data from Yahoo Finance\n",
        "2. Collecting news headlines for sentiment analysis\n",
        "3. Data preprocessing and storage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete!\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import datetime\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Create data directory if it doesn't exist\n",
        "Path('../data').mkdir(exist_ok=True)\n",
        "\n",
        "print(\"Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Download Stock Price Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading price data for 10 stocks from 2022-01-01 to 2024-12-31...\n"
          ]
        }
      ],
      "source": [
        "# Define stock tickers - starting with major tech stocks\n",
        "tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'NVDA', 'TSLA', 'NFLX', 'CRM', 'ADBE']\n",
        "\n",
        "# Date range for historical data\n",
        "start_date = \"2022-01-01\"\n",
        "end_date = \"2024-12-31\"\n",
        "\n",
        "print(f\"Downloading price data for {len(tickers)} stocks from {start_date} to {end_date}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  10 of 10 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded data shape: (752, 50)\n",
            "Date range: 2022-01-03 00:00:00 to 2024-12-30 00:00:00\n",
            "Available data for 10 stocks\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Download all data at once\n",
        "data = yf.download(tickers, start=start_date, end=end_date, group_by='ticker')\n",
        "\n",
        "if data is not None and not data.empty:\n",
        "    print(f\"Downloaded data shape: {data.shape}\")\n",
        "    print(f\"Date range: {data.index[0]} to {data.index[-1]}\")\n",
        "    print(f\"Available data for {len(tickers)} stocks\")\n",
        "else:\n",
        "    print(\"❌ Failed to download data. Check your internet connection and try again.\")\n",
        "    print(\"Note: Yahoo Finance may sometimes block requests or have temporary issues.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== DATA STRUCTURE DEBUG ===\n",
            "Data shape: (752, 50)\n",
            "Column names: ['Ticker', 'Price']\n",
            "First few columns: [('CRM', 'Open'), ('CRM', 'High'), ('CRM', 'Low'), ('CRM', 'Close'), ('CRM', 'Volume'), ('META', 'Open'), ('META', 'High'), ('META', 'Low'), ('META', 'Close'), ('META', 'Volume')]\n",
            "Sample ticker data columns: ['Open', 'High', 'Low', 'Close', 'Volume']\n",
            "Sample data:\n",
            "Price             Open        High         Low       Close     Volume\n",
            "Date                                                                 \n",
            "2022-01-03  174.542917  179.499574  174.425140  178.645645  104487900\n",
            "2022-01-04  179.254190  179.558457  175.809061  176.378342   99310400\n",
            "2022-01-05  176.290048  176.839695  171.411914  171.686737   94537600\n",
            "==================================================\n",
            "Error processing AAPL: 'Adj Close'\n",
            "Error processing MSFT: 'Adj Close'\n",
            "Error processing GOOGL: 'Adj Close'\n",
            "Error processing AMZN: 'Adj Close'\n",
            "Error processing META: 'Adj Close'\n",
            "Error processing NVDA: 'Adj Close'\n",
            "Error processing TSLA: 'Adj Close'\n",
            "Error processing NFLX: 'Adj Close'\n",
            "Error processing CRM: 'Adj Close'\n",
            "Error processing ADBE: 'Adj Close'\n",
            "\n",
            "✅ Price data collection complete!\n"
          ]
        }
      ],
      "source": [
        "# Check if data download was successful\n",
        "if data is not None and not data.empty:\n",
        "    \n",
        "    # Debug: Check data structure first\n",
        "    print(\"=== DATA STRUCTURE DEBUG ===\")\n",
        "    print(f\"Data shape: {data.shape}\")\n",
        "    print(f\"Column names: {data.columns.names}\")\n",
        "    print(f\"First few columns: {list(data.columns[:10])}\")\n",
        "    print(f\"Sample ticker data columns: {list(data[tickers[0]].columns)}\")\n",
        "    print(\"Sample data:\")\n",
        "    print(data[tickers[0]].head(3))\n",
        "    print(\"=\" * 50)\n",
        "    # Save individual stock data with technical indicators\n",
        "    for ticker in tickers:\n",
        "        try:\n",
        "            # Extract data for this ticker\n",
        "            df = data[ticker].copy()\n",
        "            \n",
        "            # Add basic technical indicators (using Close since Adj Close not available)\n",
        "            df['Returns'] = df['Close'].pct_change()\n",
        "            df['Volume_MA_20'] = df['Volume'].rolling(20).mean()\n",
        "            df['Price_MA_20'] = df['Close'].rolling(20).mean()\n",
        "            df['Price_MA_5'] = df['Close'].rolling(5).mean()\n",
        "            df['Volatility_20'] = df['Returns'].rolling(20).std()\n",
        "            \n",
        "            # Simple RSI calculation\n",
        "            delta = df['Close'].diff()\n",
        "            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
        "            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
        "            rs = gain / loss\n",
        "            df['RSI'] = 100 - (100 / (1 + rs))\n",
        "            \n",
        "            # Save to CSV\n",
        "            df.to_csv(f\"../data/{ticker}_price.csv\")\n",
        "            print(f\"Saved {ticker}: {len(df)} rows\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {ticker}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    print(\"\\n✅ Price data collection complete!\")\n",
        "else:\n",
        "    print(\"❌ Cannot process data - download failed or data is empty\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. News Headlines Collection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample headlines for AAPL (2 found):\n",
            "1. Entertainment\n",
            "2. New on Yahoo\n"
          ]
        }
      ],
      "source": [
        "def get_yahoo_headlines(ticker, max_headlines=10):\n",
        "    \"\"\"\n",
        "    Scrape recent headlines for a given stock ticker from Yahoo Finance\n",
        "    Note: This is a basic example - in production, you'd want to use proper APIs\n",
        "    \"\"\"\n",
        "    try:\n",
        "        url = f\"https://finance.yahoo.com/quote/{ticker}?p={ticker}\"\n",
        "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        \n",
        "        # Find headline elements (this may need adjustment based on Yahoo's current structure)\n",
        "        headlines = []\n",
        "        for h in soup.find_all(['h3', 'h4'], limit=max_headlines * 2):\n",
        "            text = h.text.strip()\n",
        "            if text and len(text) > 10 and len(text) < 200:\n",
        "                headlines.append(text)\n",
        "                if len(headlines) >= max_headlines:\n",
        "                    break\n",
        "        \n",
        "        return headlines\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting headlines for {ticker}: {e}\")\n",
        "        return []\n",
        "\n",
        "# Test the function\n",
        "sample_headlines = get_yahoo_headlines('AAPL', max_headlines=3)\n",
        "print(f\"Sample headlines for AAPL ({len(sample_headlines)} found):\")\n",
        "for i, headline in enumerate(sample_headlines):\n",
        "    print(f\"{i+1}. {headline}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting headlines for AAPL...\n",
            "Collecting headlines for MSFT...\n",
            "Collecting headlines for GOOGL...\n",
            "Collecting headlines for AMZN...\n",
            "Collecting headlines for META...\n",
            "Collecting headlines for NVDA...\n",
            "Collecting headlines for TSLA...\n",
            "Collecting headlines for NFLX...\n",
            "Collecting headlines for CRM...\n",
            "Collecting headlines for ADBE...\n",
            "\n",
            "✅ Collected 23 headlines total\n",
            "Headlines per stock: {'TSLA': 5, 'AAPL': 2, 'MSFT': 2, 'GOOGL': 2, 'AMZN': 2, 'META': 2, 'NVDA': 2, 'NFLX': 2, 'CRM': 2, 'ADBE': 2}\n",
            "Saved to: ../data/headlines_sample.csv\n"
          ]
        }
      ],
      "source": [
        "# Collect headlines for all tickers\n",
        "import time\n",
        "\n",
        "all_headlines = []\n",
        "\n",
        "for ticker in tickers:\n",
        "    print(f\"Collecting headlines for {ticker}...\")\n",
        "    headlines = get_yahoo_headlines(ticker, max_headlines=5)\n",
        "    \n",
        "    for headline in headlines:\n",
        "        all_headlines.append({\n",
        "            'ticker': ticker,\n",
        "            'headline': headline,\n",
        "            'date': datetime.datetime.now().strftime('%Y-%m-%d'),\n",
        "            'timestamp': datetime.datetime.now().isoformat(),\n",
        "            'source': 'yahoo_finance'\n",
        "        })\n",
        "    \n",
        "    # Be nice to the server\n",
        "    time.sleep(1)\n",
        "\n",
        "# Create DataFrame and save\n",
        "headlines_df = pd.DataFrame(all_headlines)\n",
        "headlines_df.to_csv('../data/headlines_sample.csv', index=False)\n",
        "\n",
        "print(f\"\\n✅ Collected {len(headlines_df)} headlines total\")\n",
        "print(f\"Headlines per stock: {headlines_df['ticker'].value_counts().to_dict()}\")\n",
        "print(f\"Saved to: ../data/headlines_sample.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== SAMPLE HEADLINES ===\n",
            "  ticker       headline        date                   timestamp         source\n",
            "0   AAPL  Entertainment  2025-06-29  2025-06-29T23:09:56.466219  yahoo_finance\n",
            "1   AAPL   New on Yahoo  2025-06-29  2025-06-29T23:09:56.466226  yahoo_finance\n",
            "2   MSFT  Entertainment  2025-06-29  2025-06-29T23:09:58.181409  yahoo_finance\n",
            "3   MSFT   New on Yahoo  2025-06-29  2025-06-29T23:09:58.181414  yahoo_finance\n",
            "4  GOOGL  Entertainment  2025-06-29  2025-06-29T23:09:59.858205  yahoo_finance\n",
            "5  GOOGL   New on Yahoo  2025-06-29  2025-06-29T23:09:59.858210  yahoo_finance\n",
            "6   AMZN  Entertainment  2025-06-29  2025-06-29T23:10:01.586185  yahoo_finance\n",
            "7   AMZN   New on Yahoo  2025-06-29  2025-06-29T23:10:01.586190  yahoo_finance\n",
            "8   META  Entertainment  2025-06-29  2025-06-29T23:10:03.289127  yahoo_finance\n",
            "9   META   New on Yahoo  2025-06-29  2025-06-29T23:10:03.289132  yahoo_finance\n"
          ]
        }
      ],
      "source": [
        "# Display sample of collected headlines\n",
        "print(\"=== SAMPLE HEADLINES ===\")\n",
        "print(headlines_df.head(10))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
